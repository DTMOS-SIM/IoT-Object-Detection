{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b869284",
   "metadata": {},
   "source": [
    "# Exercise 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096db99",
   "metadata": {},
   "source": [
    "### Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9125b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef0fce",
   "metadata": {},
   "source": [
    "### Class Declaration for trackable object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcb573",
   "metadata": {},
   "source": [
    "##### Each identified object will be mapped to a trackable class object where information such as:\n",
    "\n",
    "- center position of current object at frame\n",
    "- object id tagged to each object\n",
    "- the count to check if the object has already been marked (for those moving towards town)\n",
    "\n",
    "##### will be stored and processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1297996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackedObjects:\n",
    "    def __init__(self, objectID, centroid):\n",
    "\n",
    "        # store the object ID, then initialize a list of centroids\n",
    "        self.objectID = objectID\n",
    "\n",
    "        # using the current centroid\n",
    "        self.centroid = centroid\n",
    "\n",
    "        # initialize a boolean used to indicate if the object has been counted\n",
    "        self.counted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd771ab",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b13c47",
   "metadata": {},
   "source": [
    "#### Get background Model\n",
    "\n",
    "##### By using a random sampling size of 60 frames to generate a background image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74202c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for background subtraction later on\n",
    "def get_background(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # 60 frames were selected as a form of median for calculation later on\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=60)\n",
    "    # storing the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "        #add frame to array\n",
    "        frames.append(frame)\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    # return median function\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a61893",
   "metadata": {},
   "source": [
    "#### Get centroids and draw rectangles\n",
    "\n",
    "##### For every frame that is access, the objects will be identified on ONLY the main street (excluding humans and bicycles), rectangles will be drawn over the vehicles while each vehicle's center position will be appended into a higher global array based on the euclidean distance as defined at a later section of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5556c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids_draw_rectangles(all_contours):\n",
    "    for contour in all_contours:\n",
    "        # continue through the loop if contour area is less than 500...\n",
    "        # ... helps in removing noise detection\n",
    "        if cv2.contourArea(contour) < 500:\n",
    "            continue\n",
    "        # get the x-min, y-min, width, and height coordinates from the contours\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        # Cropping box detection to only bottom half of the screen\n",
    "        if y >= 250:\n",
    "            # Ensure detection is not human or bicycle\n",
    "            if w > 62 and h > 84:\n",
    "                # draw the bounding boxes\n",
    "                cv2.rectangle(orig_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "                #Get centroid of each box\n",
    "                x,y = get_centroid(x,y,w,h)\n",
    "                current_centroid = [x,y]\n",
    "                current_frame_centroids.append(current_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb971f",
   "metadata": {},
   "source": [
    "#### Check object if new or existing\n",
    "\n",
    "##### This function runs checks on every new frame of objects against the previous frame objects to determine if the are either new item where it will be added into the frame or existing item (determine by the eulidean distance of previous frame centriod to current frame centriod), where the deviation amount will not be more than 40 regardless of magnitude and the new value will be updated onto the existing object by on nearest distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fb5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_object_addition_or_updates(current_frame,previous_frame,counted):\n",
    "    for centroid in current_frame:\n",
    "        #created boolean to check if object is new\n",
    "        not_found = True\n",
    "        #Check if centroid is already from the previous DataFrame\n",
    "        for item in previous_frame:\n",
    "\n",
    "            #Check if euclidean < 20\n",
    "            if 0 <= abs(math.dist(centroid, item.centroid)) < 60:\n",
    "                #Assign new centroid to existing centroid\n",
    "                item.centroid = centroid\n",
    "                #print(\"object\" + str(item.objectID) + \"updated!\" + \" Values: \" + str(item.centroid[0]) + \" \" +  str(item.centroid[1]))\n",
    "                not_found = False\n",
    "\n",
    "        if not_found:\n",
    "            #Add new centroid to object list\n",
    "            counted = counted + 1\n",
    "            #print(\"object\" + str(counted_cars) + \"added!\" + \" Values: \" + str(current_centroid[0]) + \" \" +  str(current_centroid[1]))\n",
    "            objects.append(TrackedObjects(counted_cars,centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6851c0f",
   "metadata": {},
   "source": [
    "#### Check object if out of frame\n",
    "\n",
    "##### This function ensures that when an object leaves the specific area that we are analysing, it will be remove from the array to prevent cluttering of unwanted data causing unnecessary errors from surfacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0564e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_out_of_frame(previous_frame,current_frame):\n",
    "    for item in previous_frame:\n",
    "\n",
    "        #created boolean to check if object is out of frame\n",
    "        not_found = True\n",
    "        for centroid in current_frame:\n",
    "            #Check if euclidean < 20\n",
    "            if 0 <= abs(math.dist(centroid, item.centroid)) < 60:\n",
    "                not_found = False\n",
    "\n",
    "        if not_found:\n",
    "            #Remove out of frame objects\n",
    "            #print(\"object\" + str(item.objectID) + \"removed!\" + \" Values: \" + str(item.centroid[0]) + \" \" + str(item.centroid[1]))\n",
    "            objects.remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d0a7a",
   "metadata": {},
   "source": [
    "#### Check object if travelling to downtown (Task 2 Requirements)\n",
    "\n",
    "##### This function checks for vehicles moving towards town. This particular implementation has been done through the crossing of space technique where vehicles will be marked as cross the moment it passes across a specific marked out area. In this case, we demarcated the area (570 to 640 for x-axis and 360 to 480 for y-axis) as that is the optimal spot to obtain traffic towards downtown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07873084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_downtown_marker_crossing(current_frame):\n",
    "    global total_car\n",
    "    for item in current_frame:\n",
    "        # Check if vehicle is moving towards town\n",
    "        # Downtown marker coordinates\n",
    "        # x-axis = 480\n",
    "        # y-axis = 340 - 460\n",
    "        if (570 < item.centroid[0] <= 640) and (360 < item.centroid[1] <= 480):\n",
    "            if item.counted:\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Car detected!\")\n",
    "                item.counted = True\n",
    "                total_car = total_car + 1\n",
    "                print(\"Total Car: \", str(total_car))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06493403",
   "metadata": {},
   "source": [
    "### Algorithm for loading video file into frames for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42aa6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture('Traffic_Laramie_1.mp4')\n",
    "\n",
    "# get the background model\n",
    "background = get_background('Traffic_Laramie_1.mp4')\n",
    "# convert the background model to grayscale format\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total_duration = total_frame_count/fps\n",
    "frame_count = 0\n",
    "# declare the no of consecutive frames to analyse, the smaller the higher the accuracy of each rectangle being drawn on each frame's object(s)\n",
    "consecutive_frame = 4\n",
    "counted_cars = 0\n",
    "total_car = 0\n",
    "objects: list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3f00e",
   "metadata": {},
   "source": [
    "#### This is the algorithm to calculated the center of each contour's 4 corners after applying the rect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36cc5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(x,y,w,h):\n",
    "    return x + (w / 2), y + (h / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5439623",
   "metadata": {},
   "source": [
    "### Processing motion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9578235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car detected!\n",
      "Total Car:  1\n",
      "Car detected!\n",
      "Total Car:  2\n",
      "Car detected!\n",
      "Total Car:  3\n",
      "Car detected!\n",
      "Total Car:  4\n",
      "Cars per minute:  2\n"
     ]
    }
   ],
   "source": [
    "# Loop to start processing each current and previous frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # Check if frame available\n",
    "    if ret == True:\n",
    "        frame_count += 1\n",
    "        #Duplicate frame to ensure original colored frame stays\n",
    "        orig_frame = frame.copy()\n",
    "        # Convert the frame to grayscale first\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #Check if frame is at the very start of the processing queue\n",
    "        if frame_count % consecutive_frame == 0 or frame_count == 1:\n",
    "            frame_diff_list = []\n",
    "        # find the difference between current frame and base frame\n",
    "        frame_diff = cv2.absdiff(gray, background)\n",
    "        # thresholding to convert the frame to binary\n",
    "        ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "        # dilate the frame a bit to get some more white area...\n",
    "        # ... makes the detection of contours a bit easier\n",
    "        dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "        # append the final result into the `frame_diff_list`\n",
    "        frame_diff_list.append(dilate_frame)\n",
    "\n",
    "        if len(frame_diff_list) == consecutive_frame:\n",
    "            # add all the frames in the `frame_diff_list`\n",
    "            sum_frames = sum(frame_diff_list)\n",
    "            # find the contours around the white segmented areas\n",
    "            contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # draw the contours, not strictly necessary\n",
    "            for i, cnt in enumerate(contours):\n",
    "                cv2.drawContours(frame, contours, i, (0, 0, 255), 3)\n",
    "\n",
    "            #create new array for temporary checking of out of frame objects\n",
    "            current_frame_centroids = []\n",
    "\n",
    "            # Get all relevant box [x,y] values and append to current_frame_centroids\n",
    "            get_centroids_draw_rectangles(contours)\n",
    "\n",
    "            # Check all the existing objects and new objects\n",
    "            check_object_addition_or_updates(current_frame_centroids,objects,counted_cars)\n",
    "\n",
    "            # Check all the out of frame objects\n",
    "            check_out_of_frame(objects, current_frame_centroids)\n",
    "\n",
    "            # Check if line crosses\n",
    "            check_downtown_marker_crossing(objects)\n",
    "\n",
    "            cv2.imshow('Detected Objects', orig_frame)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "total_car_per_minute = round((1/(total_duration/60)) * total_car)\n",
    "print(\"Cars per minute: \", str(total_car_per_minute))\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd88807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
